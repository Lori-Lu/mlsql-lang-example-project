[{"kind":1,"language":"markdown","value":"## A Tour of MLSQL\n\nMLSQL is a clould-native destributed language designed for data + AI.\n\nKeywords:\n\n1. Data + AI\n2. Cloud Native\n3. Distributed\n4. Language","outputs":[]},{"kind":1,"language":"markdown","value":"## Show Language Version","outputs":[]},{"kind":2,"language":"mlsql","value":"!show version;","outputs":[]},{"kind":1,"language":"markdown","value":"## Build-In Functions ","outputs":[]},{"kind":1,"language":"markdown","value":"### !desc\n\nShow table schema.","outputs":[]},{"kind":2,"language":"mlsql","value":"select 1 as a as mockTable;\n!desc mockTable;","outputs":[]},{"kind":1,"language":"markdown","value":"### !show","outputs":[]},{"kind":2,"language":"mlsql","value":"-- show active jobs\n!show jobs;","outputs":[]},{"kind":2,"language":"mlsql","value":"-- show supported datasources\n!show datasources;","outputs":[]},{"kind":2,"language":"mlsql","value":"-- show datasource params.\n!show \"datasources/params/csv\";","outputs":[]},{"kind":2,"language":"mlsql","value":"-- show ETs\n!show et;","outputs":[]},{"kind":2,"language":"mlsql","value":"-- show ET\n!show \"et/RandomForest\";","outputs":[]},{"kind":2,"language":"mlsql","value":"-- Show ET params\n!show et/params/RandomForest;","outputs":[]},{"kind":1,"language":"markdown","value":"## !kill","outputs":[]},{"kind":2,"language":"mlsql","value":"-- kill job.\n-- We can get groupId from !show jobs;\n!kill [groupId or Job Name];","outputs":[]},{"kind":1,"language":"markdown","value":"### !last\n\nGet the last command ouput and give a name so we \ncan refrence it in later statment.","outputs":[]},{"kind":2,"language":"mlsql","value":"!hdfs -ls /tmp;\n!lastCommand named table1;\nselect * from table1 as output;","outputs":[]},{"kind":1,"language":"markdown","value":"## Data Load/Save","outputs":[]},{"kind":1,"language":"markdown","value":"### Dataset Mock","outputs":[]},{"kind":2,"language":"mlsql","value":"8-- convert json string table table\nset abc='''\n{ \"x\": 100, \"y\": 200, \"z\": 200 ,\"dataType\":\"A group\"}\n{ \"x\": 120, \"y\": 100, \"z\": 260 ,\"dataType\":\"B group\"}\n''';\n\n-- jsonStr do not support save.\nload jsonStr.`abc` as table1;","outputs":[]},{"kind":2,"language":"mlsql","value":"-- convert json string to table\n\nset rawData='''\nname,age\nzhangsan,1\nlisi,2\n''';\n\n-- csvStr do not support save.\nload csvStr.`rawData` options header=\"true\" and inferSchema=\"true\"\nas output;","outputs":[]},{"kind":1,"language":"markdown","value":"### CSV\n\nYou can speicify dir/file path.","outputs":[]},{"kind":2,"language":"mlsql","value":"load csv.`./example-data/csv/test.csv` where header=\"true\" as output;","outputs":[]},{"kind":2,"language":"mlsql","value":"save overwrite output as csv.`/tmp/testc-copfy` where header=\"true\";","outputs":[]},{"kind":1,"language":"markdown","value":"### Excel","outputs":[]},{"kind":2,"language":"mlsql","value":"load excel.`./example-data/excel/example_en.xlsx` \nwhere header=\"true\" as example_en_table;","outputs":[]},{"kind":2,"language":"mlsql","value":"save overwrite example_en_table as  excel.`./example-data/excel/example_en_copy.xlsx` \nwhere header=\"true\" ;","outputs":[]},{"kind":1,"language":"markdown","value":"### Text\n","outputs":[]},{"kind":2,"language":"mlsql","value":"-- text do not support save\nload text.`./example-data/text` as textfiles;","outputs":[]},{"kind":1,"language":"markdown","value":"### XML\n","outputs":[]},{"kind":2,"language":"mlsql","value":"-- we need plugin mlsql-ds  before load xml data.\n!plugin app add - \"mlsql-ds-3.0\";","outputs":[]},{"kind":2,"language":"mlsql","value":"load xml.`./example-data/xml/a.xml` where rowTag=\"one\" as xmlfile;","outputs":[]},{"kind":2,"language":"mlsql","value":"-- The target path `./example-data/xml/a_copy` is directory.\nsave overwrite xmlfile as xml.`./example-data/xml/a_copy` where rowTag=\"one\";","outputs":[]},{"kind":1,"language":"markdown","value":"### Parquet","outputs":[]},{"kind":2,"language":"mlsql","value":"load parquet.`./example-data/parquet` as parquetTable;","outputs":[]},{"kind":2,"language":"mlsql","value":"save overwrite parquetTable as parquet.`./example-data/xml/parquet_copy`;","outputs":[]},{"kind":1,"language":"markdown","value":"### JDBC","outputs":[]},{"kind":2,"language":"mlsql","value":"-- provide a connection\nconnect jdbc where\n url=\"jdbc:mysql://127.0.0.1:3306/wow?characterEncoding=utf8&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false\"\n and driver=\"com.mysql.jdbc.Driver\"\n and user=\"\"\n and password=\"#[[ YOUR_PASSOWRD ]]#\"\n as mysql_instance;","outputs":[]},{"kind":2,"language":"mlsql","value":"load jdbc.`mysql_instance. YOUR TABLE NAME` as mysql_table;\nselect * from mysql_table limit 10 as output;","outputs":[]},{"kind":2,"language":"mlsql","value":"-- directQuery will send the `directQuery` to MySQL and reconstruct the data as result.\nload jdbc.`mysql_instance.YOUR TABLE NAME` where directQuery='''\nselect * from YOUR TABLE NAME where a = \"b\"\n''' as newtable;","outputs":[]},{"kind":1,"language":"markdown","value":"## Variables\n\nThe concept of variables exists in most languages. \nWe can decalare/assign a variable with set statement.\n\nSome limitation:\n\n1. The lifetime scope is `request`. It means that the engine will not remember the variable after the exectuion.\n2. No any output after execution of varable decalaration.\n3. There is only one variable type: string. \n","outputs":[]},{"kind":2,"language":"mlsql","value":"set world=\"world\";","outputs":[]},{"kind":2,"language":"mlsql","value":"-- Since we do not set `world` in the same cell, the output\n-- will be `hello `\nselect \"hello ${world}\" as title \nas output;","outputs":[]},{"kind":2,"language":"mlsql","value":"-- It takes effect since the declaration in the same cell.\nset world=\"world\";\n\nselect \"hello ${world}\" as title \nas output;","outputs":[]},{"kind":1,"language":"markdown","value":"Variable assing happens in two phases:\n\n1. compile phase\n2. runtime phase\n\nBy default, the variable will execute in both phase. \nYou can specify it runs only in runtime phase.\n\nBefore the engine really execute MLSQL code, it has a prepocess(compile) phase, which do \nsome jobs like:\n\n1. `include` expand\n2. `macro functions` expand\n\nAfter that, the engine will get raw code and execute the MLSQL code.","outputs":[]},{"kind":2,"language":"mlsql","value":"/** \n   `__table_name_cache__` is a build-in variable, \n   and this line tell mlsql engine do not remenber temp table \n   in this code. For example ,the following script will create \n   temp tables like foo_table,ouput and  the engine \n   will drop them after this execution.\n**/\nset __table_name_cache__=\"false\";\n\nselect \"foo\" as foo as foo_table;\nset hello=`select foo from foo_table` where type=\"sql\";\nselect \"${hello}\" as name as output;","outputs":[]},{"kind":1,"language":"markdown","value":"Variables can also be used in function like `!if/!elif`.\nYou can reference a variable with prefix `:`.","outputs":[]},{"kind":2,"language":"mlsql","value":"select 1 as a as mockTable;\n\nset b_count=`select count(*) from mockTable ` where type=\"sql\" and mode=\"runtime\";\n\n!if ''':b_count > 11 ''';\n    \n    select 1 as a from b as final_table;\n!else;    \n    select 2 as a from b as final_table;\n!fi;    \n\nselect * from final_table as output;","outputs":[]},{"kind":1,"language":"markdown","value":"There are five types of variables:\n\n1. text (default)\n2. conf\n3. shell\n5. sql\n6. defaultParam\n\nThe most used are text/sql/defaultParam.","outputs":[]},{"kind":2,"language":"mlsql","value":"-- text type\nset hello=\"world\";","outputs":[]},{"kind":2,"language":"mlsql","value":"-- conf type\nset spark.sql.shuffle.partitions=200 where type=\"conf\";","outputs":[]},{"kind":2,"language":"mlsql","value":"-- shell type (only works in darwin/linux)\n\nset date=`date` where type=\"shell\";\nselect \"${date}\" as dt as output;","outputs":[]},{"kind":2,"language":"mlsql","value":"-- sql type\n\nset date=`select date_sub(CAST(current_timestamp() as DATE), 1) as dt` \nwhere type=\"sql\";\n\nselect \"${date}\" as dt as output;\n","outputs":[]},{"kind":1,"language":"markdown","value":"### defaultParam type\nonce if you set this type, the variable will take effect only when there\nis no the same variable is declared before.\n\nIn the following code, the output will be `foo` instead of `bar`.\n\nIf you remove the first line, then the output will be `bar`.","outputs":[]},{"kind":2,"language":"mlsql","value":"set hello=\"foo\";\nset hello=\"bar\" where type=\"defaultParam\";\n\nselect \"${hello}\" as name as output;","outputs":[]},{"kind":1,"language":"markdown","value":"### build-in variable","outputs":[]},{"kind":2,"language":"mlsql","value":"set jack='''\n hello today is:${date.toString(\"yyyyMMdd\")}\n''';\n\nselect \"${jack}\" as name as output;","outputs":[]},{"kind":1,"language":"markdown","value":"## Train/Run\n\nTrain/Run has the same structure. Normally, Train is used to run some ML algorithms and\nRun is for data processing.\n\nThe statment structure is like following:\n\n```\ntrain/run  [TABLE NAME] as [ET NAME].`` where [OPTIONS]\nas [NEW TABLE NAME];\n```\n\nET is from the Machine learning and the full name is  Estimator/Transformer. In MLSQL , wen can \ndevelop custom ET to enhance our language ability.\n\nThere are so many ETs in MSLQL already.","outputs":[]},{"kind":2,"language":"mlsql","value":"-- get all et names.\n!show et;\n\n-- get the output in last sentence.\n!lastCommand named ets;\n\n-- filter the table ets.\nselect * from ets where name like \"%Assert%\" as output;","outputs":[]},{"kind":2,"language":"mlsql","value":"-- no output but you can run it without error.\nrun command as EmptyTable.`` \nas ouputTable;","outputs":[]},{"kind":1,"language":"markdown","value":"## Register\n\nRegister can be used in three cases:\n\n1. Register model\n2. Register native UDF\n3. Register Watermark in streaming job\n\nWe will introduce how to use in the first two cases.","outputs":[]},{"kind":1,"language":"markdown","value":"### Register model","outputs":[]},{"kind":1,"language":"markdown","value":"The plugin mlsql-mllib is required in this code example.","outputs":[]},{"kind":2,"language":"mlsql","value":"!plugin app add - \"mlsql-mllib-3.0\";","outputs":[]},{"kind":2,"language":"mlsql","value":"-- prepare a model\nrun command as SampleDatasetExt.`` \nwhere columns=\"id,features,label\" \nand size=\"100000\" \nand featuresSize=\"100\" \nand labelSize=\"2\" \nas mockData;\n\nrun command as SampleDatasetExt.`` \nwhere columns=\"id,features,label\" \nand size=\"10000\" \nand featuresSize=\"100\" \nand labelSize=\"2\" \nas testMockData;\n\nselect id,vec_dense(features) as features,label from mockData as trainData;\nselect id,vec_dense(features) as features,label from testMockData as testData;\n\ntrain trainData as AutoMLExt.`/tmp/auto_ml_model` where\nalgos=\"GBTs,LinearRegression,LogisticRegression,NaiveBayes,RandomForest\"\nand keepVersion=\"true\"\nand evaluateTable=\"testData\";","outputs":[]},{"kind":2,"language":"mlsql","value":"-- register this model as a UDF\nregister AutoMLExt.`/tmp/auto_ml_model` as two_catagory_predict;\n\n-- then you can use the UDF two_catagory_predict from register statement.\nselect id,two_catagory_predict(features) as predicted,label from testData as output;","outputs":[]},{"kind":1,"language":"markdown","value":"Register also supports where clause.  \n\nYou can specify which model from models generated in the train stage with `algIndex`\nor you can let the system choose the best model by specifing `autoSelectByMetric`.","outputs":[]},{"kind":2,"language":"mlsql","value":"register AutoMLExt.`/tmp/auto_ml_model` as two_catagory_predict\nwhere autoSelectByMetric=\"f1\";","outputs":[]},{"kind":1,"language":"markdown","value":"### Register UDF (Scala/Java)","outputs":[]},{"kind":2,"language":"mlsql","value":"register ScriptUDF.`` as arrayLast \nwhere lang=\"scala\"\nand code='''def apply(a:Seq[String])={\n      a.last\n}'''\nand udfType=\"udf\";\n\nselect arrayLast(array(\"a\",\"b\")) as lastChar as output;","outputs":[]},{"kind":1,"language":"markdown","value":"## Distributed Python\n\nPlease make sure you have the following packages installed in your python enviroment:\n\n```\npyarrow==4.0.1\nray>=1.3.0\npandas>=1.0.5; python_version < '3.7'\npandas>=1.2.0; python_version >= '3.7'\nrequests\nmatplotlib~=3.3.4\nuuid~=1.30\npyjava\n```","outputs":[]},{"kind":2,"language":"mlsql","value":"!python env \"PYTHON_ENV=source /Users/allwefantasy/opt/anaconda3/bin/activate ray1.6.0\";\nload excel.`./example-data/excel/user-behavior.xlsx` where header=\"true\"  as wow;\n!desc wow json;","outputs":[]},{"kind":1,"language":"markdown","value":"In the following code example, we will show you how to process \ndata in python with ray. \n\nThere are three modes which is specified by the second parameter in `RayContext.connect`:\n\n1. local\n2. external ray url(e.g. 127.0.0.1:10001)\n3. None\n\n`local` mode only works in ray version >= 1.6.0. It will start ray everytime we execute the python script.\n\nThe second mode the system will connect an already existed ray cluster.\n\n`None` means we will run in python client instead of ray.\n","outputs":[]},{"kind":2,"language":"python","value":"#%python\n#%input=wow\n#%schema=st(field(count,long))\n\nimport ray\nfrom pyjava.api.mlsql import PythonContext, RayContext\nfrom pyjava import rayfix\nfrom typing import List\n\ncontext: PythonContext = context\n\nray_contex = RayContext.connect(globals(), \"local\")\n\ndata_refs:List[str] = ray_contex.data_servers()\n\n@ray.remote\n@rayfix.last\ndef train(data_ref:str):\n    data = RayContext.collect_from([data_ref])\n    counter = 0\n    for _ in data:\n        counter += 1\n    return counter    \n\njob_refs = [train.remote(data_ref) for data_ref in data_refs ]\nsums = [ray.get(job_ref) for job_ref in job_refs]\nfinal_count = sum(sums)\ncontext.build_result([{\"count\":final_count}])","outputs":[]},{"kind":1,"language":"markdown","value":"In this code, we use Python to compute the count of all records. \n\nThe difference between this code and the normal Python code is that the function `train` runs in parallel(distribute if the ray is clsuter mode).\n\nThe developers can get all data refefrences by invoking `ray_contex.data_servers()` which returns the connections list of table `wow` , and using `RayContext.collect_from([data_ref])`  to get the row iterator of any one of the data refs.","outputs":[]},{"kind":2,"language":"python","value":"#%python\n#%input=wow\n#%schema={\"type\":\"struct\",\"fields\":[{\"name\":\"user_id\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"item_id\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"catagory_id\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"behavior_type\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"timestamp\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"datatime\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}\n#%dataMode=data\n\nimport ray\nfrom pyjava.api.mlsql import PythonContext, RayContext\nfrom pyjava import rayfix\nfrom typing import List\n\ncontext: PythonContext = context\n\nray_contex = RayContext.connect(globals(), \"local\")\n\ndef process(row):    \n    row[\"user_id\"]=\"wow\"\n    return row\n\nray_contex.foreach(process)","outputs":[]},{"kind":1,"language":"markdown","value":"In this code, we try to modify the value of column `user_id`. It's a little boring and easy to make typo issues if we write the schema manually. \n\nYou can use `!desc wow json;` to get the schema with json style and paste it in the comment `#%schema=...`.\n\nThis time, we define a funciton called `process` which have the user custom logical and pass it to `ray_contex.foreach` and it will\napply the `process` to every row in `wow` table.","outputs":[]},{"kind":1,"language":"markdown","value":"## Delta Lake","outputs":[]},{"kind":2,"language":"mlsql","value":"select 1 as a as bTable;\n-- save overwrite delta.``","outputs":[]}]