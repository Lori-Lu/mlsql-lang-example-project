[{"kind":1,"language":"markdown","value":"## 分布式Tensorflow Cifar10数据训练\n\n在该Notebook我们会演示如何使用MLSQL对Cifar10数据集进行分布式TF训练。","outputs":[]},{"kind":2,"language":"mlsql","value":"-- 加载 ResizeImage.mlsqlnb已经预处理好的图片数据\n-- 因为涉及到list 目录，所以比较慢，我们可以把加载的结果保存下\nload binaryFile.`/tmp/size-28x28/*.png` as cifar10; \nsave overwrite cifar10 as delta.`dataset.cifar10` where fileNum=\"4\";","outputs":[{"mime":"x-application/mlsql-notebook","value":"{\n\t\"schema\": {\n\t\t\"type\": \"struct\",\n\t\t\"fields\": [\n\t\t\t{\n\t\t\t\t\"name\": \"owner\",\n\t\t\t\t\"type\": \"string\",\n\t\t\t\t\"nullable\": true,\n\t\t\t\t\"metadata\": {}\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"name\": \"jobType\",\n\t\t\t\t\"type\": \"string\",\n\t\t\t\t\"nullable\": true,\n\t\t\t\t\"metadata\": {}\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"name\": \"jobName\",\n\t\t\t\t\"type\": \"string\",\n\t\t\t\t\"nullable\": true,\n\t\t\t\t\"metadata\": {}\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"name\": \"jobContent\",\n\t\t\t\t\"type\": \"string\",\n\t\t\t\t\"nullable\": true,\n\t\t\t\t\"metadata\": {}\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"name\": \"groupId\",\n\t\t\t\t\"type\": \"string\",\n\t\t\t\t\"nullable\": true,\n\t\t\t\t\"metadata\": {}\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"name\": \"progress\",\n\t\t\t\t\"type\": {\n\t\t\t\t\t\"type\": \"struct\",\n\t\t\t\t\t\"fields\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"name\": \"totalJob\",\n\t\t\t\t\t\t\t\"type\": \"long\",\n\t\t\t\t\t\t\t\"nullable\": false,\n\t\t\t\t\t\t\t\"metadata\": {}\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"name\": \"currentJobIndex\",\n\t\t\t\t\t\t\t\"type\": \"long\",\n\t\t\t\t\t\t\t\"nullable\": false,\n\t\t\t\t\t\t\t\"metadata\": {}\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"name\": \"script\",\n\t\t\t\t\t\t\t\"type\": \"string\",\n\t\t\t\t\t\t\t\"nullable\": true,\n\t\t\t\t\t\t\t\"metadata\": {}\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t\"nullable\": true,\n\t\t\t\t\"metadata\": {}\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"name\": \"startTime\",\n\t\t\t\t\"type\": \"long\",\n\t\t\t\t\"nullable\": false,\n\t\t\t\t\"metadata\": {}\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"name\": \"timeout\",\n\t\t\t\t\"type\": \"long\",\n\t\t\t\t\"nullable\": false,\n\t\t\t\t\"metadata\": {}\n\t\t\t}\n\t\t]\n\t},\n\t\"data\": [\n\t\t{\n\t\t\t\"owner\": \"admin\",\n\t\t\t\"jobType\": \"script\",\n\t\t\t\"jobName\": \"3266fe8c-0e73-4fad-925e-dcb8e28fa977\",\n\t\t\t\"jobContent\": \"-- 加载 ResizeImage.mlsqlnb已经预处理好的图片数据\\n-- 因为涉及到list 目录，所以比较慢，我们可以把加载的结果保存下\\nload binaryFile.`/tmp/size-28x28/*.png` as cifar10; \\nsave overwrite cifar10 as delta.`dataset.cifar10` where fileNum=\\\"4\\\";\",\n\t\t\t\"groupId\": \"740fd1f9-3034-4ea6-9293-326b401862aa\",\n\t\t\t\"progress\": {\n\t\t\t\t\"totalJob\": 1,\n\t\t\t\t\"currentJobIndex\": 1,\n\t\t\t\t\"script\": \"save overwrite cifar10 as delta.`dataset.cifar10` where fileNum=\\\"4\\\"\"\n\t\t\t},\n\t\t\t\"startTime\": 1631064878259,\n\t\t\t\"timeout\": -1\n\t\t}\n\t]\n}"}]},{"kind":2,"language":"mlsql","value":"load delta.`dataset.cifar10` as cifar10;","outputs":[]},{"kind":2,"language":"python","value":"#%python\n#%input=cifar10\n#%output=mnist_model\n#%cache=true\n#%schema=file\n#%dataMode=model\n\nfrom functools import reduce\nimport os\nimport ray\nimport numpy as np\nfrom tensorflow.keras import models,layers\nfrom tensorflow.keras import utils as np_utils\nfrom pyjava.api.mlsql import RayContext\nfrom pyjava.storage import streaming_tar\n\n\nray_context = RayContext.connect(globals(),\"127.0.0.1:10001\")\ndata_servers = ray_context.data_servers()\nreplica_num = len(data_servers)\nprint(f\"total workers {replica_num}\")\ndef data_partition_creater(data_server):\n    temp_data = [item for item in RayContext.collect_from([data_server])]\n    train_images = np.array([np.array(item[\"image\"]) for item in temp_data])\n    train_labels = np_utils.to_categorical(np.array([item[\"label\"] for item in temp_data])    )\n    train_images = train_images.reshape((len(temp_data),28*28))\n    return train_images,train_labels    \n\ndef create_tf_model():    \n    network = models.Sequential()\n    network.add(layers.Dense(512,activation=\"relu\",input_shape=(28*28,)))\n    network.add(layers.Dense(10,activation=\"softmax\"))\n    network.compile(optimizer=\"sgd\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n    return network\n\n@ray.remote\nclass Network(object):\n    def __init__(self,data_server):\n        self.model = create_tf_model()\n        # you can also save the data to local disk if the data is \n        # not fit in memory        \n        self.train_images,self.train_labels = data_partition_creater(data_server)\n\n\n    def train(self):\n        history = self.model.fit(self.train_images,self.train_labels,batch_size=128)\n        return history.history\n\n    def get_weights(self):\n        return self.model.get_weights()\n\n    def set_weights(self, weights):\n        # Note that for simplicity this does not handle the optimizer state.\n        self.model.set_weights(weights)\n\n    def get_final_model(self):\n        model_path = os.path.join(\"/\",\"tmp\",\"minist_model\")\n        self.model.save(model_path)\n        model_binary = [item for item in streaming_tar.build_rows_from_file(model_path)]\n        return model_binary\n    def shutdown(self):\n        ray.actor.exit_actor()\n\nworkers = [Network.remote(data_server) for data_server in data_servers]\nray.get([worker.train.remote() for worker in workers])\n_weights = ray.get([worker.get_weights.remote() for worker in workers])\n\ndef epoch_train(weights):  \n    sum_weights = reduce(lambda a,b: [(a1 + b1) for a1,b1 in zip(a,b)],weights)\n    averaged_weights = [layer/replica_num for layer in sum_weights]\n    ray.get([worker.set_weights.remote(averaged_weights) for worker in workers])\n    ray.get([worker.train.remote() for worker in workers])\n    return ray.get([worker.get_weights.remote() for worker in workers])\n\nfor epoch in range(6):\n   _weights = epoch_train(_weights)\n\nmodel_binary = ray.get(workers[0].get_final_model.remote())\n[worker.shutdown.remote() for worker in workers]\nray_context.build_result(model_binary)","outputs":[]},{"kind":2,"language":"mlsql","value":"save overwrite mnist_model as delta.`ai_model.cifar_model`;","outputs":[]},{"kind":2,"language":"mlsql","value":"load delta.`ai_model.cifar_model` as cifar_model;","outputs":[]},{"kind":2,"language":"mlsql","value":"register Ray.`cifar_model` as model_predict where \nmaxConcurrency=\"8\"\nand debugMode=\"true\"\nand registerCode='''\n\nimport ray\nimport numpy as np\nfrom pyjava.api.mlsql import RayContext\nfrom pyjava.udf import UDFMaster,UDFWorker,UDFBuilder,UDFBuildInFunc\n\nray_context = RayContext.connect(globals(), context.conf[\"rayAddress\"])\n\ndef predict_func(model,v):\n    train_images = np.array([v])\n    train_images = train_images.reshape((1,28*28))\n    predictions = model.predict(train_images)\n    return {\"value\":[[float(np.argmax(item)) for item in predictions]]}\n\nUDFBuilder.build(ray_context,UDFBuildInFunc.init_tf,predict_func)\n\n''' and \npredictCode='''\n\nimport ray\nfrom pyjava.api.mlsql import RayContext\nfrom pyjava.udf import UDFMaster,UDFWorker,UDFBuilder,UDFBuildInFunc\n\nray_context = RayContext.connect(globals(), context.conf[\"rayAddress\"])\nUDFBuilder.apply(ray_context)\n\n'''\n;","outputs":[]},{"kind":2,"language":"mlsql","value":"","outputs":[]}]